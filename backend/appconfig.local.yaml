# Local App Configuration (non-secrets)
# Mirrors what you'd store in Azure App Configuration
# (e.g., as a single blob under key "quizzical:appsettings" or as hierarchical keys)

quizzical:
  app:
    name: "Quizzical"
    environment: "local"        # local | dev | staging | prod
    debug: true

  feature_flags:
    flow_mode: "agent"          # "local" | "agent"

  cors:
    origins:
      - "http://localhost:5173"
      - "http://127.0.0.1:5173"

  project:
    api_prefix: "/api/v1"

  # Retrieval policy (central, applies to all agent tools)
  retrieval:
    policy: "media_only"        # off | media_only | auto
    allow_wikipedia: false      # gate Wikipedia usage
    allow_web: false            # gate general web search usage
    max_calls_per_run: 0        # hard cap per session/run (0 = no network)
    # optional allow-list for web_search; domains only, no scheme
    allowed_domains: []         # e.g., ["www.imdb.com","www.themoviedb.org"]

  quiz:
    min_characters: 4
    max_characters: 6
    baseline_questions_n: 5
    max_options_m: 4
    max_total_questions: 20
    min_questions_before_early_finish: 6
    early_finish_confidence: 0.9
    first_step_timeout_s: 60.0
    stream_budget_s: 30.0
    # Bound parallel LLM calls for character generation.
    # Set to null to auto-pick (bounded in code), or an integer >= 1.
    character_concurrency: 4

  agent:
    max_retries: 3

  llm:
    # Global per-call timeout used by parallel character creation (and reused by question gen)
    per_call_timeout_s: 30

    tools:
      initial_planner:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 800
        timeout_s: 18
        json_output: true

      character_list_generator:
        model: "gpt-4o-mini"
        temperature: 0.3
        max_output_tokens: 1200
        timeout_s: 18
        json_output: true

      synopsis_generator:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 600
        timeout_s: 18
        json_output: true

      profile_writer:
        model: "gpt-4o-mini"
        temperature: 0.4
        max_output_tokens: 1600
        timeout_s: 18
        json_output: true

      profile_improver:
        model: "gpt-4o-mini"
        temperature: 0.3
        max_output_tokens: 1600
        timeout_s: 18
        json_output: true

      character_selector:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 1000
        timeout_s: 18
        json_output: true

      question_generator:
        model: "gpt-4o-mini"
        temperature: 0.4
        max_output_tokens: 1200
        timeout_s: 60
        json_output: true

      next_question_generator:
        model: "gpt-4o-mini"
        temperature: 0.4
        max_output_tokens: 800
        timeout_s: 18
        json_output: true

      final_profile_writer:
        model: "gpt-4o-mini"
        temperature: 0.3
        max_output_tokens: 1000
        timeout_s: 18
        json_output: true

      safety_checker:
        model: "gpt-4o-mini"
        temperature: 0.0
        max_output_tokens: 200
        timeout_s: 10
        json_output: true

      error_analyzer:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 600
        timeout_s: 12
        json_output: true

      failure_explainer:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 500
        timeout_s: 12
        json_output: true

      image_prompt_enhancer:
        model: "gpt-4o-mini"
        temperature: 0.6
        max_output_tokens: 600
        timeout_s: 18
        json_output: true

      decision_maker:
        model: "gpt-4o-mini"
        temperature: 0.2
        max_output_tokens: 800
        timeout_s: 18
        json_output: true

      # Present for completeness; disabled by retrieval policy above.
      web_search:
        model: "o4-mini"
        temperature: 0.2
        max_output_tokens: 1200
        timeout_s: 20
        json_output: false
        effort: "low"
        allowed_domains: []   # will be overridden by retrieval.allowed_domains if provided
        user_location:
          type: "approximate"
          country: "US"
          city: "Seattle"
          region: "WA"
          timezone: "America/Los_Angeles"
        include_sources: true
        tool_choice: "auto"

    # Optional prompt overrides; if omitted, defaults are used from prompts.py
    prompts: {}
